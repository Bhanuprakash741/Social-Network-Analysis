{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhanuprakash741/Social-Network-Analysis/blob/main/Social_Network_Analysis_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "!pip install torch_geometric"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "FHagCjaoc64x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CflsQxn2cjNK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Deep learning libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import Planetoid, FacebookPagePage\n",
        "from torch_geometric.utils import to_networkx\n",
        "from torch_geometric.nn import GCNConv, GATConv, HeteroConv, SAGEConv\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load datasets\n",
        "def load_datasets():\n",
        "    # Cora dataset (homogeneous)\n",
        "    cora = Planetoid(root='data/Cora', name='Cora')\n",
        "\n",
        "    # Facebook dataset\n",
        "    facebook = FacebookPagePage(root='data/Facebook')\n",
        "\n",
        "    # Twitter dataset is not available in PyTorch Geometric, so we'll create synthetic data\n",
        "    twitter = None  # We'll handle this in the HetGNN section\n",
        "\n",
        "    return cora, facebook, twitter\n",
        "\n",
        "cora, facebook, twitter = load_datasets()\n",
        "\n",
        "# Dataset analysis function (modified to handle None dataset)\n",
        "def analyze_dataset(dataset, name):\n",
        "    if dataset is None:\n",
        "        print(f\"\\n{name} Dataset not available, will use synthetic data for HetGNN\")\n",
        "        return None\n",
        "\n",
        "    print(f\"\\n{name} Dataset Info:\")\n",
        "    print(\"====================\")\n",
        "    print(f\"Number of nodes: {dataset[0].num_nodes}\")\n",
        "    print(f\"Number of edges: {dataset[0].num_edges}\")\n",
        "    print(f\"Number of node features: {dataset[0].num_node_features}\")\n",
        "    print(f\"Number of classes: {dataset[0].y.unique().shape[0]}\")\n",
        "    if hasattr(dataset[0], 'edge_type'):\n",
        "        print(f\"Heterogeneous graph with {dataset[0].edge_type.unique().shape[0]} edge types\")\n",
        "\n",
        "    # Plot degree distribution\n",
        "    g = to_networkx(dataset[0], to_undirected=True)\n",
        "    degrees = [d for n, d in g.degree()]\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.histplot(degrees, bins=30, kde=True)\n",
        "    plt.title(f'{name} Degree Distribution')\n",
        "    plt.xlabel('Degree')\n",
        "    plt.ylabel('Count')\n",
        "\n",
        "    # Plot graph (sampled for large networks)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    if len(g) > 1000:\n",
        "        sampled_nodes = np.random.choice(list(g.nodes()), 300, replace=False)\n",
        "        sub_g = g.subgraph(sampled_nodes)\n",
        "    else:\n",
        "        sub_g = g\n",
        "\n",
        "    pos = nx.spring_layout(sub_g, seed=42)\n",
        "    nx.draw(sub_g, pos, node_size=20, alpha=0.6, width=0.5)\n",
        "    plt.title(f'{name} Network Structure (Sampled)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return g\n",
        "\n",
        "# Analyze each dataset\n",
        "print(\"Loading and analyzing datasets...\")\n",
        "cora_g = analyze_dataset(cora, \"Cora\")\n",
        "facebook_g = analyze_dataset(facebook, \"Facebook\")\n",
        "analyze_dataset(twitter, \"Twitter\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_features, hidden_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "def train_gcn(model, data, epochs=200):\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        val_acc = test_gcn(model, data, data.val_mask)\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        if epoch % 50 == 0:\n",
        "            print(f'Epoch: {epoch:03d}, Loss: {loss.item():.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "    return train_losses, val_accuracies\n",
        "\n",
        "def test_gcn(model, data, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data.x, data.edge_index)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct = pred[mask] == data.y[mask]\n",
        "        acc = int(correct.sum()) / int(mask.sum())\n",
        "    return acc\n",
        "\n",
        "# Prepare Cora dataset for GCN\n",
        "data = cora[0].to(device)\n",
        "data.x = data.x.to(device)\n",
        "data.edge_index = data.edge_index.to(device)\n",
        "data.y = data.y.to(device)\n",
        "\n",
        "# Initialize and train GCN\n",
        "gcn = GCN(num_features=data.num_features,\n",
        "          hidden_channels=16,\n",
        "          num_classes=data.y.unique().shape[0]).to(device)\n",
        "\n",
        "print(\"\\nTraining GCN on Cora dataset...\")\n",
        "train_losses, val_accuracies = train_gcn(gcn, data)\n",
        "\n",
        "# Plot training results\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.title('GCN Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(val_accuracies, label='Validation Accuracy', color='orange')\n",
        "plt.title('GCN Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Test GCN\n",
        "test_acc = test_gcn(gcn, data, data.test_mask)\n",
        "print(f'\\nGCN Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Visualize embeddings\n",
        "def visualize_embeddings(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data.x, data.edge_index)\n",
        "        h = out.cpu().numpy()\n",
        "\n",
        "    # Reduce dimensions with t-SNE\n",
        "    tsne = TSNE(n_components=2, random_state=42)\n",
        "    h_2d = tsne.fit_transform(h)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    scatter = plt.scatter(h_2d[:, 0], h_2d[:, 1], c=data.y.cpu(), cmap='Set1', alpha=0.6)\n",
        "    plt.legend(*scatter.legend_elements(), title=\"Classes\")\n",
        "    plt.title('GCN Node Embeddings Visualization (t-SNE)')\n",
        "    plt.show()\n",
        "\n",
        "visualize_embeddings(gcn, data)"
      ],
      "metadata": {
        "id": "pstR409oeKkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, num_features, hidden_channels, num_classes, heads=8):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(num_features, hidden_channels, heads=heads, dropout=0.6)\n",
        "        self.conv2 = GATConv(hidden_channels * heads, num_classes, heads=1, concat=False, dropout=0.6)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "def train_gat(model, data, epochs=200):\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        val_acc = test_gat(model, data, data.val_mask)\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        if epoch % 50 == 0:\n",
        "            print(f'Epoch: {epoch:03d}, Loss: {loss.item():.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "    return train_losses, val_accuracies\n",
        "\n",
        "def test_gat(model, data, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data.x, data.edge_index)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct = pred[mask] == data.y[mask]\n",
        "        acc = int(correct.sum()) / int(mask.sum())\n",
        "    return acc\n",
        "\n",
        "# Initialize and train GAT\n",
        "gat = GAT(num_features=data.num_features,\n",
        "          hidden_channels=8,\n",
        "          num_classes=data.y.unique().shape[0],\n",
        "          heads=8).to(device)\n",
        "\n",
        "print(\"\\nTraining GAT on Cora dataset...\")\n",
        "train_losses_gat, val_accuracies_gat = train_gat(gat, data)\n",
        "\n",
        "# Plot training results\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses_gat, label='Training Loss')\n",
        "plt.title('GAT Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(val_accuracies_gat, label='Validation Accuracy', color='orange')\n",
        "plt.title('GAT Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Test GAT\n",
        "test_acc_gat = test_gat(gat, data, data.test_mask)\n",
        "print(f'\\nGAT Test Accuracy: {test_acc_gat:.4f}')\n",
        "\n",
        "# Visualize GAT embeddings\n",
        "visualize_embeddings(gat, data)\n"
      ],
      "metadata": {
        "id": "V6J0KI41dDvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_hetero_data():\n",
        "    data = HeteroData()\n",
        "\n",
        "    # User nodes\n",
        "    num_users = 1000\n",
        "    data['user'].x = torch.randn(num_users, 64)  # User features\n",
        "    data['user'].y = torch.randint(0, 3, (num_users,))  # User classes\n",
        "\n",
        "    # Post nodes\n",
        "    num_posts = 5000\n",
        "    data['post'].x = torch.randn(num_posts, 128)  # Post features\n",
        "\n",
        "    # Create relationships\n",
        "    # User-post (written) relationships\n",
        "    written_edges = torch.randint(0, num_users, (2, 3000))\n",
        "    data['user', 'writes', 'post'].edge_index = written_edges\n",
        "\n",
        "    # User-user (follows) relationships\n",
        "    follow_edges = torch.randint(0, num_users, (2, 5000))\n",
        "    data['user', 'follows', 'user'].edge_index = follow_edges\n",
        "\n",
        "    # Post-post (reply) relationships\n",
        "    reply_edges = torch.randint(0, num_posts, (2, 2000))\n",
        "    data['post', 'reply_to', 'post'].edge_index = reply_edges\n",
        "\n",
        "    # Add some masks\n",
        "    data['user'].train_mask = torch.zeros(num_users, dtype=torch.bool)\n",
        "    data['user'].val_mask = torch.zeros(num_users, dtype=torch.bool)\n",
        "    data['user'].test_mask = torch.zeros(num_users, dtype=torch.bool)\n",
        "\n",
        "    # Select random samples for masks\n",
        "    idx = torch.randperm(num_users)\n",
        "    data['user'].train_mask[idx[:600]] = True\n",
        "    data['user'].val_mask[idx[600:800]] = True\n",
        "    data['user'].test_mask[idx[800:]] = True\n",
        "\n",
        "    return data\n",
        "\n",
        "hetero_data = create_hetero_data().to(device)\n",
        "\n",
        "class HetGNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, num_classes, metadata):\n",
        "        super().__init__()\n",
        "        self.convs = torch.nn.ModuleDict()\n",
        "\n",
        "        # Get input dimensions for each node type\n",
        "        in_channels_user = hetero_data['user'].x.size(1)\n",
        "        in_channels_post = hetero_data['post'].x.size(1)\n",
        "\n",
        "        # Create separate GNN layers for each edge type\n",
        "        for edge_type in metadata[1]:\n",
        "            if edge_type == ('user', 'follows', 'user'):\n",
        "                self.convs['user_follows_user'] = GATConv(in_channels_user, hidden_channels)\n",
        "            elif edge_type == ('user', 'writes', 'post'):\n",
        "                self.convs['user_writes_post'] = SAGEConv((in_channels_user, in_channels_post), hidden_channels)\n",
        "            elif edge_type == ('post', 'reply_to', 'post'):\n",
        "                self.convs['post_reply_to_post'] = GCNConv(in_channels_post, hidden_channels)\n",
        "\n",
        "        self.lin = torch.nn.Linear(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict):\n",
        "        # Apply separate convolutions for each edge type\n",
        "        out_dict = {}\n",
        "\n",
        "        # Process user-follows-user relationships\n",
        "        if 'user_follows_user' in self.convs:\n",
        "            edge_type = ('user', 'follows', 'user')\n",
        "            out = self.convs['user_follows_user'](x_dict['user'], edge_index_dict[edge_type])\n",
        "            if 'user' in out_dict:\n",
        "                out_dict['user'] = (out_dict['user'] + out) / 2\n",
        "            else:\n",
        "                out_dict['user'] = out\n",
        "\n",
        "        # Process user-writes-post relationships\n",
        "        if 'user_writes_post' in self.convs:\n",
        "            edge_type = ('user', 'writes', 'post')\n",
        "            out = self.convs['user_writes_post'](\n",
        "                (x_dict['user'], x_dict['post']),\n",
        "                edge_index_dict[edge_type]\n",
        "            )\n",
        "            if 'post' in out_dict:\n",
        "                out_dict['post'] = (out_dict['post'] + out) / 2\n",
        "            else:\n",
        "                out_dict['post'] = out\n",
        "\n",
        "        # Process post-reply_to-post relationships\n",
        "        if 'post_reply_to_post' in self.convs:\n",
        "            edge_type = ('post', 'reply_to', 'post')\n",
        "            out = self.convs['post_reply_to_post'](x_dict['post'], edge_index_dict[edge_type])\n",
        "            if 'post' in out_dict:\n",
        "                out_dict['post'] = (out_dict['post'] + out) / 2\n",
        "            else:\n",
        "                out_dict['post'] = out\n",
        "\n",
        "        # We're only classifying users in this example\n",
        "        return self.lin(out_dict['user'])\n",
        "\n",
        "    def encode(self, x_dict, edge_index_dict):\n",
        "        # Get node embeddings\n",
        "        out_dict = {}\n",
        "\n",
        "        # Process user-follows-user relationships\n",
        "        if 'user_follows_user' in self.convs:\n",
        "            edge_type = ('user', 'follows', 'user')\n",
        "            out = self.convs['user_follows_user'](x_dict['user'], edge_index_dict[edge_type])\n",
        "            if 'user' in out_dict:\n",
        "                out_dict['user'] = (out_dict['user'] + out) / 2\n",
        "            else:\n",
        "                out_dict['user'] = out\n",
        "\n",
        "        # Process user-writes-post relationships\n",
        "        if 'user_writes_post' in self.convs:\n",
        "            edge_type = ('user', 'writes', 'post')\n",
        "            out = self.convs['user_writes_post'](\n",
        "                (x_dict['user'], x_dict['post']),\n",
        "                edge_index_dict[edge_type]\n",
        "            )\n",
        "            if 'post' in out_dict:\n",
        "                out_dict['post'] = (out_dict['post'] + out) / 2\n",
        "            else:\n",
        "                out_dict['post'] = out\n",
        "\n",
        "        # Process post-reply_to-post relationships\n",
        "        if 'post_reply_to_post' in self.convs:\n",
        "            edge_type = ('post', 'reply_to', 'post')\n",
        "            out = self.convs['post_reply_to_post'](x_dict['post'], edge_index_dict[edge_type])\n",
        "            if 'post' in out_dict:\n",
        "                out_dict['post'] = (out_dict['post'] + out) / 2\n",
        "            else:\n",
        "                out_dict['post'] = out\n",
        "\n",
        "        return out_dict\n",
        "\n",
        "def final_test_hetgnn(model, data):\n",
        "    \"\"\"\n",
        "    Evaluates the HetGNN model and returns test accuracy, confusion matrix, and classification report.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data.x_dict, data.edge_index_dict)\n",
        "        pred = out[data['user'].test_mask].argmax(dim=1)\n",
        "        y_true = data['user'].y[data['user'].test_mask]\n",
        "\n",
        "        acc = int(pred.eq(y_true).sum()) / int(data['user'].test_mask.sum())\n",
        "\n",
        "        cm = confusion_matrix(y_true.cpu(), pred.cpu())\n",
        "        report = classification_report(y_true.cpu(), pred.cpu())\n",
        "\n",
        "    return acc, cm, report\n",
        "\n",
        "def train_hetgnn(model, data, epochs=100):\n",
        "    \"\"\"\n",
        "    Trains the HetGNN model and returns training losses and validation accuracies.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x_dict, data.edge_index_dict)\n",
        "\n",
        "        # Calculate loss only on the labeled user nodes in the training set\n",
        "        loss = criterion(out[data['user'].train_mask], data['user'].y[data['user'].train_mask])\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        # Calculate validation accuracy\n",
        "        val_acc, _, _ = final_test_hetgnn(model, data)  # Use the test function with the validation mask\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        # Print progress every 50 epochs\n",
        "        if epoch % 50 == 0:\n",
        "            print(f'Epoch: {epoch:03d}, Loss: {loss.item():.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "    return train_losses, val_accuracies\n",
        "def visualize_hetero_embeddings(model, data):\n",
        "    \"\"\"\n",
        "    Visualizes embeddings for the HetGNN model\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        embeddings = model.encode(data.x_dict, data.edge_index_dict)\n",
        "        user_embeddings = embeddings['user'].cpu().numpy()\n",
        "\n",
        "    tsne = TSNE(n_components=2, random_state=42)\n",
        "    h_2d = tsne.fit_transform(user_embeddings)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    scatter = plt.scatter(h_2d[:, 0], h_2d[:, 1], c=data['user'].y.cpu(), cmap='Set1', alpha=0.6)\n",
        "    plt.legend(*scatter.legend_elements(), title=\"Classes\")\n",
        "    plt.title('HetGNN Node Embeddings Visualization (t-SNE)')\n",
        "    plt.show()\n",
        "\n",
        "# Initialize and train HetGNN\n",
        "metadata = hetero_data.metadata()\n",
        "hetgnn = HetGNN(hidden_channels=32,\n",
        "                num_classes=hetero_data['user'].y.unique().shape[0],\n",
        "                metadata=metadata).to(device)\n",
        "\n",
        "print(\"\\nTraining HetGNN on synthetic heterogeneous dataset...\")\n",
        "train_losses_het, val_accuracies_het = train_hetgnn(hetgnn, hetero_data)\n",
        "\n",
        "# Plot training results\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses_het, label='Training Loss')\n",
        "plt.title('HetGNN Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(val_accuracies_het, label='Validation Accuracy', color='orange')\n",
        "plt.title('HetGNN Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Test HetGNN\n",
        "test_acc_het, cm_het, report_het = final_test_hetgnn(hetgnn, hetero_data)\n",
        "print(f'\\nHetGNN Test Accuracy: {test_acc_het:.4f}')\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report_het)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_het, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('HetGNN Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# Visualize heterogeneous embeddings\n",
        "visualize_hetero_embeddings(hetgnn, hetero_data)"
      ],
      "metadata": {
        "id": "klyX1ARbdDxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare model performances\n",
        "models = ['GCN', 'GAT', 'HetGNN']\n",
        "test_accs = [test_acc, test_acc_gat, test_acc_het]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(models, test_accs, color=['blue', 'orange', 'green'])\n",
        "plt.title('Model Comparison on Test Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "for i, v in enumerate(test_accs):\n",
        "    plt.text(i, v + 0.02, f\"{v:.4f}\", ha='center')\n",
        "plt.show()\n",
        "\n",
        "# Compare training curves\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_losses, label='GCN Training Loss')\n",
        "plt.plot(train_losses_gat, label='GAT Training Loss')\n",
        "plt.plot(train_losses_het, label='HetGNN Training Loss')\n",
        "plt.title('Training Loss Comparison')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(val_accuracies, label='GCN Validation Accuracy')\n",
        "plt.plot(val_accuracies_gat, label='GAT Validation Accuracy')\n",
        "plt.plot(val_accuracies_het, label='HetGNN Validation Accuracy')\n",
        "plt.title('Validation Accuracy Comparison')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Community detection comparison (using GCN, GAT, and HetGNN embeddings)\n",
        "def detect_communities(embeddings, true_labels, title):\n",
        "    from sklearn.cluster import KMeans\n",
        "\n",
        "    # Cluster embeddings\n",
        "    kmeans = KMeans(n_clusters=true_labels.unique().shape[0], random_state=42)\n",
        "    clusters = kmeans.fit_predict(embeddings)\n",
        "\n",
        "    # Calculate adjusted rand score\n",
        "    from sklearn.metrics import adjusted_rand_score\n",
        "    ari = adjusted_rand_score(true_labels.cpu(), clusters)\n",
        "\n",
        "    # Plot clusters\n",
        "    tsne = TSNE(n_components=2, random_state=42)\n",
        "    emb_2d = tsne.fit_transform(embeddings)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.scatter(emb_2d[:, 0], emb_2d[:, 1], c=clusters, cmap='Set1', alpha=0.6)\n",
        "    plt.title(f'{title} - Detected Communities (ARI: {ari:.4f})')\n",
        "    plt.show()\n",
        "\n",
        "    return ari\n",
        "\n",
        "# Get embeddings from each model\n",
        "gcn.eval()\n",
        "gat.eval()\n",
        "hetgnn.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    # GCN embeddings\n",
        "    gcn_emb = gcn.conv1(data.x, data.edge_index)\n",
        "    gcn_emb = gcn.conv2(gcn_emb, data.edge_index)\n",
        "\n",
        "    # GAT embeddings\n",
        "    gat_emb = gat.conv1(data.x, data.edge_index)\n",
        "    gat_emb = gat.conv2(gat_emb, data.edge_index)\n",
        "\n",
        "    # HetGNN embeddings (users only)\n",
        "    het_emb = hetgnn.encode(\n",
        "        {node_type: hetero_data[node_type].x for node_type in hetero_data.node_types},\n",
        "        hetero_data.edge_index_dict\n",
        "    )['user']\n",
        "\n",
        "# Community detection\n",
        "print(\"\\nCommunity Detection Performance:\")\n",
        "ari_gcn = detect_communities(gcn_emb.cpu().numpy(), data.y, \"GCN\")\n",
        "ari_gat = detect_communities(gat_emb.cpu().numpy(), data.y, \"GAT\")\n",
        "ari_het = detect_communities(het_emb.cpu().numpy(), hetero_data['user'].y, \"HetGNN\")\n",
        "\n",
        "# Plot community detection performance\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(['GCN', 'GAT', 'HetGNN'], [ari_gcn, ari_gat, ari_het], color=['blue', 'orange', 'green'])\n",
        "plt.title('Community Detection Performance (Adjusted Rand Index)')\n",
        "plt.ylabel('ARI Score')\n",
        "plt.ylim(0, 1)\n",
        "for i, v in enumerate([ari_gcn, ari_gat, ari_het]):\n",
        "    plt.text(i, v + 0.02, f\"{v:.4f}\", ha='center')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qWU9T4e_dD1S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}